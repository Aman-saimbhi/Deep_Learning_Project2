{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U \"ray[tune]\"","metadata":{"id":"fo8FM0mczoGc","outputId":"ae37597c-379f-4a80-8148-16daa3906770","execution":{"iopub.status.busy":"2022-05-17T23:20:29.045348Z","iopub.execute_input":"2022-05-17T23:20:29.045662Z","iopub.status.idle":"2022-05-17T23:20:38.725508Z","shell.execute_reply.started":"2022-05-17T23:20:29.045627Z","shell.execute_reply":"2022-05-17T23:20:38.724683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.models as models\ndef my_model():\n#     efficientnet_b0 = models.efficientnet_b0()\n    model = models.densenet161()\n#     model = models.inception_v3()\n    return model","metadata":{"id":"oDvxQxTbCpKJ","execution":{"iopub.status.busy":"2022-05-17T23:20:53.509144Z","iopub.execute_input":"2022-05-17T23:20:53.509417Z","iopub.status.idle":"2022-05-17T23:20:53.513488Z","shell.execute_reply.started":"2022-05-17T23:20:53.509372Z","shell.execute_reply":"2022-05-17T23:20:53.512715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import random_split\nimport torchvision\nimport torchvision.transforms as transforms\nfrom ray import tune\nfrom ray.tune import CLIReporter\nfrom ray.tune.schedulers import ASHAScheduler","metadata":{"id":"YVQnTeIlCcrO","execution":{"iopub.status.busy":"2022-05-17T23:21:04.88042Z","iopub.execute_input":"2022-05-17T23:21:04.880959Z","iopub.status.idle":"2022-05-17T23:21:05.101365Z","shell.execute_reply.started":"2022-05-17T23:21:04.880901Z","shell.execute_reply":"2022-05-17T23:21:05.10066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_cifar(config, checkpoint_dir=None, data_dir=None):\n\n    net = my_model()\n    device = \"cpu\"\n    if torch.cuda.is_available():\n        device = \"cuda:0\"\n        if torch.cuda.device_count() > 1:\n            net = nn.DataParallel(net)\n    net.to(device)\n    criterion = nn.CrossEntropyLoss()\n    if config[\"optimizer\"] == 'sgd':\n      optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"],momentum=0.9, weight_decay=5e-4)\n    \n    if config[\"optimizer\"] == 'adam':\n      optimizer = optim.Adam(net.parameters(), lr=config[\"lr\"], weight_decay=5e-4)\t\n    if config[\"optimizer\"] == 'adagrad':\n      optimizer = optim.Adagrad(net.parameters(), lr=config[\"lr\"],weight_decay=5e-4)\n    \n        \n        \n    if checkpoint_dir:\n        model_state, optimizer_state = torch.load(\n            os.path.join(checkpoint_dir, \"checkpoint\"))\n        net.load_state_dict(model_state)\n        optimizer.load_state_dict(optimizer_state)\n\n    trainset, testset = load_data(data_dir)\n\n    test_abs = int(len(trainset) * 0.8)\n    train_subset, val_subset = random_split(\n        trainset, [test_abs, len(trainset) - test_abs])\n\n    trainloader = torch.utils.data.DataLoader(\n        train_subset,\n        batch_size=int(config[\"batch_size\"]),\n        shuffle=True,\n        num_workers=8)\n    valloader = torch.utils.data.DataLoader(\n        val_subset,\n        batch_size=int(config[\"batch_size\"]),\n        shuffle=True,\n        num_workers=8)\n\n    for epoch in range(25):  # loop over the dataset multiple times\n        running_loss = 0.0\n        epoch_steps = 0\n        for i, data in enumerate(trainloader, 0):\n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            # print statistics\n            running_loss += loss.item()\n            epoch_steps += 1\n            if i % 2000 == 1999:  # print every 2000 mini-batches\n                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n                                                running_loss / epoch_steps))\n                running_loss = 0.0\n\n        # Validation loss\n        val_loss = 0.0\n        val_steps = 0\n        total = 0\n        correct = 0\n        for i, data in enumerate(valloader, 0):\n            with torch.no_grad():\n                inputs, labels = data\n                inputs, labels = inputs.to(device), labels.to(device)\n\n                outputs = net(inputs)\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n                loss = criterion(outputs, labels)\n                val_loss += loss.cpu().numpy()\n                val_steps += 1\n\n        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n            path = os.path.join(checkpoint_dir, \"checkpoint\")\n            torch.save((net.state_dict(), optimizer.state_dict()), path)\n\n        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n    print(\"Finished Training\")","metadata":{"id":"I1K_Sy4aon7z","execution":{"iopub.status.busy":"2022-05-17T23:21:17.489339Z","iopub.execute_input":"2022-05-17T23:21:17.489811Z","iopub.status.idle":"2022-05-17T23:21:17.510933Z","shell.execute_reply.started":"2022-05-17T23:21:17.489771Z","shell.execute_reply":"2022-05-17T23:21:17.510124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(data_dir=\"./data\"):\n    transform_train = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        #transforms.RandomVerticalFlip(),\n        transforms.ToTensor(),\n        #transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n\n    transform_test = transforms.Compose([\n        transforms.ToTensor(),\n        #transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n\n    trainset = torchvision.datasets.CIFAR10(\n        root='./data', train=True, download=True, transform=transform_train)\n    trainloader = torch.utils.data.DataLoader(\n        trainset, shuffle=True, num_workers=2)\n\n    testset = torchvision.datasets.CIFAR10(\n        root='./data', train=False, download=True, transform=transform_test)\n\n\n    testloader = torch.utils.data.DataLoader(\n        testset, shuffle=False, num_workers=2)\n\n    return trainset, testset","metadata":{"id":"ItvqLIFkyRET","execution":{"iopub.status.busy":"2022-05-17T23:21:19.119016Z","iopub.execute_input":"2022-05-17T23:21:19.119574Z","iopub.status.idle":"2022-05-17T23:21:19.12672Z","shell.execute_reply.started":"2022-05-17T23:21:19.119535Z","shell.execute_reply":"2022-05-17T23:21:19.125914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_accuracy(net, device=\"cpu\"):\n    trainset, testset = load_data()\n\n    testloader = torch.utils.data.DataLoader(\n        testset, batch_size=4, shuffle=False, num_workers=2)\n\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in testloader:\n            images, labels = data\n            images, labels = images.to(device), labels.to(device)\n            outputs = net(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    return correct / total","metadata":{"id":"BmAGHjdppXwS","execution":{"iopub.status.busy":"2022-05-17T23:21:19.712512Z","iopub.execute_input":"2022-05-17T23:21:19.713116Z","iopub.status.idle":"2022-05-17T23:21:19.719781Z","shell.execute_reply.started":"2022-05-17T23:21:19.713084Z","shell.execute_reply":"2022-05-17T23:21:19.718986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mainfunc(num_samples=10, max_num_epochs=10, gpus_per_trial=1):\n    data_dir = os.path.abspath(\"./data\")\n    config = {\n        \"optimizer\":tune.choice([\"adam\", \"sgd\", \"adagrad\"]),\n        \"lr\": tune.loguniform(1e-3, 1e-1),\n        \"batch_size\": tune.choice([16, 64, 128, 256])\n    }\n    scheduler = ASHAScheduler(\n        metric=\"loss\",\n        mode=\"min\",\n        max_t=max_num_epochs,\n        grace_period=1,\n        reduction_factor=2)\n    reporter = CLIReporter(\n        parameter_columns=[\"lr\", \"batch_size\",\"optimizer\"],\n        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n\n    result = tune.run(\n        tune.with_parameters(train_cifar, data_dir=data_dir),\n        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n        config=config,\n        num_samples=num_samples,\n        scheduler=scheduler,\n        progress_reporter=reporter)\n    \n    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n    print(\"Best trial config: {}\".format(best_trial.config))\n    print(\"Best trial final validation loss: {}\".format(\n        best_trial.last_result[\"loss\"]))\n    print(\"Best trial final validation accuracy: {}\".format(\n        best_trial.last_result[\"accuracy\"]))\n\n    best_trained_model = project1_model()\n    device = \"cpu\"\n    if torch.cuda.is_available():\n        device = \"cuda:0\"\n        if gpus_per_trial > 1:\n            best_trained_model = nn.DataParallel(best_trained_model)\n    best_trained_model.to(device)\n\n    best_checkpoint_dir = best_trial.checkpoint.value\n    model_state, optimizer_state = torch.load(os.path.join(\n        best_checkpoint_dir, \"checkpoint\"))\n    best_trained_model.load_state_dict(model_state)\n\n    test_acc = test_accuracy(best_trained_model, device)\n    print(\"Best trial test set accuracy: {}\".format(test_acc))","metadata":{"id":"5njdQoi-pxiF","execution":{"iopub.status.busy":"2022-05-17T23:21:20.421409Z","iopub.execute_input":"2022-05-17T23:21:20.421951Z","iopub.status.idle":"2022-05-17T23:21:20.432836Z","shell.execute_reply.started":"2022-05-17T23:21:20.421909Z","shell.execute_reply":"2022-05-17T23:21:20.432169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mainfunc(num_samples=10, max_num_epochs=25, gpus_per_trial=1)","metadata":{"id":"x3ukX0kxp0y7","outputId":"45587625-541b-4b9c-b1a0-9d4020ebb303","execution":{"iopub.status.busy":"2022-05-17T23:21:30.851961Z","iopub.execute_input":"2022-05-17T23:21:30.85278Z","iopub.status.idle":"2022-05-17T23:24:07.176213Z","shell.execute_reply.started":"2022-05-17T23:21:30.852741Z","shell.execute_reply":"2022-05-17T23:24:07.174148Z"},"trusted":true},"execution_count":null,"outputs":[]}]}