{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Project2_Module1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yhzp6FWgjc5K",
        "outputId": "5eef099c-0eb1-44b2-b019-2021a570f13a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Deep_Learning_Project2'...\n",
            "remote: Enumerating objects: 107, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 107 (delta 43), reused 86 (delta 24), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (107/107), 15.91 MiB | 18.92 MiB/s, done.\n",
            "Resolving deltas: 100% (43/43), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Aman-saimbhi/Deep_Learning_Project2.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Deep_Learning_Project2/Densenet.py --dataset cifar10 --arch densenet --p 0.5 --epochs 25 --lr 0.01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG6forx_jtKN",
        "outputId": "3b4f1109-3ec5-430a-f1c8-64e7df8710bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing dataset cifar10\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
            "170499072it [00:03, 43712538.84it/s]                   \n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "==> creating model 'densenet'\n",
            "    Total params: 28.68M\n",
            "\n",
            "Epoch: [1 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.005s | Batch: 0.366s | Total: 0:02:23 | ETA: 0:00:01 | Loss: 1.8910 | top1:  34.3320 | top5:  84.5720\n",
            "\u001b[?25h\u001b[?25l/content/Deep_Learning_Project2/Densenet.py:300: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.006s | Batch: 0.218s | Total: 0:00:21 | ETA: 0:00:01 | Loss: 1.6667 | top1:  45.3300 | top5:  92.0000\n",
            "\n",
            "Epoch: [2 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.004s | Batch: 0.304s | Total: 0:01:58 | ETA: 0:00:01 | Loss: 1.5118 | top1:  46.4860 | top5:  91.8340\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.005s | Batch: 0.142s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 1.3031 | top1:  54.3500 | top5:  95.2200\n",
            "\n",
            "Epoch: [3 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.004s | Batch: 0.303s | Total: 0:01:58 | ETA: 0:00:01 | Loss: 1.3173 | top1:  53.6940 | top5:  93.9660\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.005s | Batch: 0.142s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 1.2479 | top1:  58.3200 | top5:  95.4900\n",
            "\n",
            "Epoch: [4 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.005s | Batch: 0.303s | Total: 0:01:58 | ETA: 0:00:01 | Loss: 1.2052 | top1:  57.2680 | top5:  95.2240\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.005s | Batch: 0.141s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 1.1295 | top1:  62.5200 | top5:  96.7100\n",
            "\n",
            "Epoch: [5 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.005s | Batch: 0.304s | Total: 0:01:58 | ETA: 0:00:01 | Loss: 1.1276 | top1:  60.5260 | top5:  95.8180\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.005s | Batch: 0.142s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 0.9495 | top1:  66.8700 | top5:  97.3700\n",
            "\n",
            "Epoch: [6 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.005s | Batch: 0.303s | Total: 0:01:58 | ETA: 0:00:01 | Loss: 1.0480 | top1:  63.0280 | top5:  96.3280\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.005s | Batch: 0.142s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 0.9164 | top1:  69.1000 | top5:  97.5200\n",
            "\n",
            "Epoch: [7 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.004s | Batch: 0.304s | Total: 0:01:58 | ETA: 0:00:01 | Loss: 0.9854 | top1:  65.6080 | top5:  96.9200\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.005s | Batch: 0.142s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 0.9608 | top1:  67.0800 | top5:  97.2800\n",
            "\n",
            "Epoch: [8 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.004s | Batch: 0.303s | Total: 0:01:58 | ETA: 0:00:01 | Loss: 0.9450 | top1:  66.7480 | top5:  97.0260\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.006s | Batch: 0.143s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 0.8828 | top1:  69.4600 | top5:  97.7800\n",
            "\n",
            "Epoch: [9 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.005s | Batch: 0.305s | Total: 0:01:59 | ETA: 0:00:01 | Loss: 0.8917 | top1:  68.6900 | top5:  97.4020\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.005s | Batch: 0.142s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 0.9715 | top1:  67.3900 | top5:  97.4400\n",
            "\n",
            "Epoch: [10 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.004s | Batch: 0.305s | Total: 0:01:59 | ETA: 0:00:01 | Loss: 0.8760 | top1:  69.4600 | top5:  97.6200\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.005s | Batch: 0.141s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 0.7870 | top1:  72.4900 | top5:  97.9200\n",
            "\n",
            "Epoch: [11 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.005s | Batch: 0.304s | Total: 0:01:58 | ETA: 0:00:01 | Loss: 0.8300 | top1:  70.9400 | top5:  97.8040\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.005s | Batch: 0.143s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 0.8599 | top1:  73.5600 | top5:  98.0000\n",
            "\n",
            "Epoch: [12 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.004s | Batch: 0.304s | Total: 0:01:58 | ETA: 0:00:01 | Loss: 0.8051 | top1:  71.6100 | top5:  97.8820\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.005s | Batch: 0.141s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 0.7393 | top1:  74.7700 | top5:  98.4700\n",
            "\n",
            "Epoch: [13 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.005s | Batch: 0.304s | Total: 0:01:58 | ETA: 0:00:01 | Loss: 0.7782 | top1:  72.7020 | top5:  97.9600\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.005s | Batch: 0.143s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 0.6822 | top1:  76.6600 | top5:  98.5400\n",
            "\n",
            "Epoch: [14 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.005s | Batch: 0.304s | Total: 0:01:58 | ETA: 0:00:01 | Loss: 0.7474 | top1:  73.7240 | top5:  98.2380\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.005s | Batch: 0.142s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 0.6856 | top1:  76.4300 | top5:  98.4500\n",
            "\n",
            "Epoch: [15 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.004s | Batch: 0.303s | Total: 0:01:58 | ETA: 0:00:01 | Loss: 0.7304 | top1:  74.4480 | top5:  98.2500\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.006s | Batch: 0.143s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 0.6840 | top1:  77.3900 | top5:  98.5300\n",
            "\n",
            "Epoch: [16 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.004s | Batch: 0.303s | Total: 0:01:58 | ETA: 0:00:01 | Loss: 0.7064 | top1:  75.1220 | top5:  98.4140\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.005s | Batch: 0.142s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 0.6934 | top1:  77.1000 | top5:  98.3800\n",
            "\n",
            "Epoch: [17 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.004s | Batch: 0.303s | Total: 0:01:58 | ETA: 0:00:01 | Loss: 0.6819 | top1:  75.9620 | top5:  98.4700\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.005s | Batch: 0.142s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 0.7339 | top1:  75.6900 | top5:  98.2100\n",
            "\n",
            "Epoch: [18 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.005s | Batch: 0.303s | Total: 0:01:58 | ETA: 0:00:01 | Loss: 0.6697 | top1:  76.2880 | top5:  98.6140\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.005s | Batch: 0.142s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 0.6464 | top1:  78.2100 | top5:  98.6100\n",
            "\n",
            "Epoch: [19 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.005s | Batch: 0.303s | Total: 0:01:58 | ETA: 0:00:01 | Loss: 0.6536 | top1:  76.6620 | top5:  98.6840\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.005s | Batch: 0.142s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 0.5942 | top1:  79.6700 | top5:  98.8200\n",
            "\n",
            "Epoch: [20 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.004s | Batch: 0.303s | Total: 0:01:58 | ETA: 0:00:01 | Loss: 0.6337 | top1:  77.6820 | top5:  98.7360\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.005s | Batch: 0.142s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 0.6740 | top1:  77.7200 | top5:  98.6100\n",
            "\n",
            "Epoch: [21 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.004s | Batch: 0.303s | Total: 0:01:58 | ETA: 0:00:01 | Loss: 0.6146 | top1:  78.2600 | top5:  98.7960\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.005s | Batch: 0.142s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 0.6022 | top1:  79.5800 | top5:  98.7300\n",
            "\n",
            "Epoch: [22 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.005s | Batch: 0.303s | Total: 0:01:58 | ETA: 0:00:01 | Loss: 0.6026 | top1:  78.7120 | top5:  98.9040\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.005s | Batch: 0.142s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 0.6209 | top1:  78.8600 | top5:  98.7100\n",
            "\n",
            "Epoch: [23 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.004s | Batch: 0.303s | Total: 0:01:58 | ETA: 0:00:01 | Loss: 0.5906 | top1:  79.3980 | top5:  98.8940\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.005s | Batch: 0.141s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 0.5874 | top1:  80.7200 | top5:  98.8500\n",
            "\n",
            "Epoch: [24 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.005s | Batch: 0.303s | Total: 0:01:58 | ETA: 0:00:01 | Loss: 0.5782 | top1:  79.7560 | top5:  98.9960\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.005s | Batch: 0.142s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 0.6070 | top1:  79.5500 | top5:  98.8500\n",
            "\n",
            "Epoch: [25 | 25] LR: 0.010000\n",
            "\u001b[KProcessing |################################| (391/391) Data: 0.005s | Batch: 0.303s | Total: 0:01:58 | ETA: 0:00:01 | Loss: 0.5692 | top1:  79.9180 | top5:  98.9820\n",
            "\u001b[KProcessing |################################| (100/100) Data: 0.005s | Batch: 0.142s | Total: 0:00:14 | ETA: 0:00:01 | Loss: 0.5787 | top1:  80.4900 | top5:  98.9100\n",
            "\u001b[?25hThe PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
            "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
            "Best acc:\n",
            "80.72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0iVdSQkVz_TH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}